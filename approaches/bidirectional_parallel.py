# approaches/bidirectional_parallel.py
import asyncio
from typing import Dict, Any, List, Tuple
import networkx as nx
import itertools
import time

from models import SubTask
from .base import DAGApproach
from core import LLMClient, DAGProcessor
from core.validation_utils import DAGValidator


class BidirectionalParallelApproach(DAGApproach):    
    def __init__(self):
        super().__init__("bidirectional_parallel")
        self.workflow_engine = None  # WorkflowEngine ëŒ€ì‹  ì§ì ‘ êµ¬í˜„
        self.LOW_CONF_THRESHOLD = 0.4
        self.CUTOFF_THRESHOLD = 0.5
        self.BATCH_SIZE = 8  # ë³‘ë ¬ ì²˜ë¦¬ ë°°ì¹˜ í¬ê¸°
    
    def _build_dag_impl(self, subtasks: List[SubTask], original_task: str) -> Tuple[nx.DiGraph, Dict[str, Any]]:
        """ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•œ bidirectional DAG êµ¬ì„±"""
        
        print("âš¡ BIDIRECTIONAL-PARALLEL APPROACH - Using async batch processing...")
        print(f"   Original task: {original_task[:100]}...")
        print(f"   Subtasks ({len(subtasks)}): {[st.id for st in subtasks]}")
        
        # DAG ì´ˆê¸°í™”
        dag = nx.DiGraph()
        for st in subtasks:
            dag.add_node(st.id, obj=st, description=st.description)
        
        # ì˜ì¡´ì„± ìŒ ìƒì„± (bidirectional)
        dependency_pairs = []
        for a, b in itertools.combinations(subtasks, 2):
            dependency_pairs.append((a, b))  # A -> B
            dependency_pairs.append((b, a))  # B -> A
        
        n_pairs = len(dependency_pairs)
        print(f"   ðŸ“Š Total dependency checks: {n_pairs} (bidirectional pairs)")
        print(f"   ðŸ“¦ Batch size: {self.BATCH_SIZE} (processing {(n_pairs-1)//self.BATCH_SIZE + 1} batches)")
        
        # ë¹„ë™ê¸° ë³‘ë ¬ ì˜ì¡´ì„± ë¶„ì„
        start_time = time.time()
        dependency_results = asyncio.run(self.llm_client.batch_dependency_analysis(
            dependency_pairs, original_task, batch_size=self.BATCH_SIZE
        ))
        analysis_time = time.time() - start_time
        
        print(f"   âš¡ Parallel analysis completed in {analysis_time:.2f}s")
        print(f"   ðŸ“Š Analysis rate: {len(dependency_pairs)/analysis_time:.1f} pairs/second")
        
        # DAG êµ¬ì„±
        edge_conf_map = {}
        low_conf_candidates = []
        resource_calls = 0
        
        for (task_a, task_b), (dependent, confidence) in dependency_results.items():
            if dependent and confidence >= self.CUTOFF_THRESHOLD:
                # ë†’ì€ ì‹ ë¢°ë„ ì˜ì¡´ì„± ì¶”ê°€
                if not dag.has_edge(task_b.id, task_a.id):  # ì—­ë°©í–¥ ì¶©ëŒ í™•ì¸
                    dag.add_edge(task_a.id, task_b.id, confidence=confidence, 
                               has_resource_conflict=False, shared_resources=[])
                    edge_conf_map[(task_a.id, task_b.id)] = confidence
                    resource_calls += 1
            elif dependent and confidence >= self.LOW_CONF_THRESHOLD:
                # ë‚®ì€ ì‹ ë¢°ë„ í›„ë³´
                low_conf_candidates.append((task_a.id, task_b.id, confidence))
        
        # ë‚®ì€ ì‹ ë¢°ë„ ì—£ì§€ ì¶”ê°€ (ì¶©ëŒ ì—†ëŠ” ê²½ìš°ë§Œ)
        for u, v, c in sorted(low_conf_candidates, key=lambda x: -x[2]):
            if not dag.has_edge(u, v) and not dag.has_edge(v, u):
                dag.add_edge(u, v, confidence=round(c, 3),
                           has_resource_conflict=False, shared_resources=[])
        
        print(f"   ðŸ“Š Edges added: {dag.number_of_edges()} (high conf: {resource_calls}, low conf: {dag.number_of_edges()-resource_calls})")
        
        # ì‚¬ì´í´ í•´ê²°
        dag = self.dag_processor.resolve_cycles_intelligently(dag, edge_conf_map)
        
        if not nx.is_directed_acyclic_graph(dag):
            raise ValueError("Graph contains cycles after resolution")
        
        # í›„ì²˜ë¦¬
        self.dag_processor.post_process_graph(dag)
        dag = self.dag_processor.apply_rule_based_pruning(dag)
        
        print(f"   âœ… Final DAG: {dag.number_of_nodes()} nodes, {dag.number_of_edges()} edges")
        print(f"   ðŸ“Š Node IDs: {list(dag.nodes())}")
        print(f"   ðŸ“Š Edge pairs: {list(dag.edges())}")
        
        metrics = {
            "llm_dependency_calls": n_pairs,
            "llm_resource_calls": 0,  # ë¦¬ì†ŒìŠ¤ ì¶©ëŒì€ ê°„ì†Œí™”
            "total_llm_calls": n_pairs,
            "analysis_time": analysis_time,
            "pairs_per_second": n_pairs / analysis_time if analysis_time > 0 else 0,
            "batch_size": self.BATCH_SIZE,
            "parallel_optimization": True
        }
        
        return dag, metrics